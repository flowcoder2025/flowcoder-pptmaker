/**
 * Gemini AI ì„œë²„ í”„ë¡ì‹œ API
 *
 * POST /api/gemini/generate - ìŠ¬ë¼ì´ë“œ ì½˜í…ì¸  ìƒì„±
 *
 * ğŸ”’ ë³´ì•ˆ: API í‚¤ë¥¼ ì„œë²„ì—ì„œë§Œ ì‚¬ìš©í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ë…¸ì¶œ ë°©ì§€
 */

import { NextRequest, NextResponse } from 'next/server'
import { GoogleGenerativeAI } from '@google/generative-ai'
import { getCurrentUserId } from '@/lib/auth'
import { logger } from '@/lib/logger'
import { geminiGenerateRequestSchema, validateRequest } from '@/lib/validations'

// ============================================
// ì„œë²„ ì „ìš© Gemini ì„¤ì •
// ============================================

// ğŸ”’ ì„œë²„ ì „ìš© API í‚¤ (NEXT_PUBLIC_ ì œê±°)
const getServerApiKey = (): string => {
  const key = process.env.GEMINI_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY
  if (!key) {
    throw new Error('GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš”')
  }
  return key
}

// Gemini ëª¨ë¸ ì„¤ì •
const GEMINI_CONFIG = {
  flash: {
    model: 'gemini-2.0-flash',
    temperature: 0.3,
    maxOutputTokens: 16384,
  },
  pro: {
    model: 'gemini-2.5-pro-preview-06-05',
    temperature: 0.3,
    maxOutputTokens: 32768,
  },
} as const

// ============================================
// Rate Limiting (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ê¸°ë°˜)
// ============================================

const rateLimitMap = new Map<string, { count: number; resetTime: number }>()
const RATE_LIMIT = {
  maxRequests: 10, // ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜
  windowMs: 60 * 1000, // 1ë¶„
}

function checkRateLimit(userId: string): boolean {
  const now = Date.now()
  const userLimit = rateLimitMap.get(userId)

  if (!userLimit || now > userLimit.resetTime) {
    rateLimitMap.set(userId, { count: 1, resetTime: now + RATE_LIMIT.windowMs })
    return true
  }

  if (userLimit.count >= RATE_LIMIT.maxRequests) {
    return false
  }

  userLimit.count++
  return true
}

// ============================================
// POST /api/gemini/generate
// ============================================

interface GenerateResponse {
  content: string
  usage?: {
    promptTokens: number
    completionTokens: number
    totalTokens: number
  }
}

export async function POST(request: NextRequest): Promise<NextResponse> {
  const startTime = Date.now()

  try {
    // 1. ì¸ì¦ ì²´í¬
    const userId = await getCurrentUserId()
    if (!userId) {
      logger.warn('Gemini API ë¯¸ì¸ì¦ ì ‘ê·¼ ì‹œë„')
      return NextResponse.json(
        { error: 'ë¡œê·¸ì¸ì´ í•„ìš”í•´ìš”' },
        { status: 401 }
      )
    }

    // 2. Rate Limiting
    if (!checkRateLimit(userId)) {
      logger.warn('Gemini API Rate Limit ì´ˆê³¼', { userId })
      return NextResponse.json(
        { error: 'ìš”ì²­ì´ ë„ˆë¬´ ë§ì•„ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' },
        { status: 429 }
      )
    }

    // 3. Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦
    const body = await request.json()
    const validation = validateRequest(geminiGenerateRequestSchema, body)
    if (!validation.success) {
      return NextResponse.json(
        { error: validation.error },
        { status: 400 }
      )
    }

    const { prompt, useProModel, maxTokens } = validation.data

    // 5. Gemini API í˜¸ì¶œ
    const config = useProModel ? GEMINI_CONFIG.pro : GEMINI_CONFIG.flash
    const modelName = useProModel ? 'Pro' : 'Flash'

    logger.info(`Gemini ${modelName} ìƒì„± ì‹œì‘`, { userId, promptLength: prompt.length })

    const genAI = new GoogleGenerativeAI(getServerApiKey())
    const model = genAI.getGenerativeModel({
      model: config.model,
      generationConfig: {
        temperature: config.temperature,
        maxOutputTokens: maxTokens || config.maxOutputTokens,
      },
    })

    // ì¬ì‹œë„ ë¡œì§
    const MAX_RETRIES = 3
    const RETRY_DELAYS = [2000, 4000, 8000]
    let lastError: Error | null = null

    for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {
      try {
        if (attempt > 0) {
          const delay = RETRY_DELAYS[attempt - 1]
          logger.info(`Gemini ${modelName} ì¬ì‹œë„`, { attempt, delay })
          await new Promise(resolve => setTimeout(resolve, delay))
        }

        const result = await model.generateContent(prompt)
        const content = result.response.text()

        // 6. ì‘ë‹µ ì²˜ë¦¬
        const duration = Date.now() - startTime
        const usage = result.response.usageMetadata

        logger.info(`Gemini ${modelName} ìƒì„± ì™„ë£Œ`, {
          userId,
          duration,
          contentLength: content.length,
          tokens: usage?.totalTokenCount,
        })

        const response: GenerateResponse = {
          content,
          usage: usage ? {
            promptTokens: usage.promptTokenCount || 0,
            completionTokens: usage.candidatesTokenCount || 0,
            totalTokens: usage.totalTokenCount || 0,
          } : undefined,
        }

        return NextResponse.json(response)
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error))
        const isServerOverloaded = lastError.message.includes('503') ||
                                    lastError.message.includes('overloaded')

        if (!isServerOverloaded || attempt === MAX_RETRIES) {
          throw lastError
        }
      }
    }

    throw lastError || new Error('ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
    logger.error('Gemini API í˜¸ì¶œ ì‹¤íŒ¨', error)

    // ì—ëŸ¬ íƒ€ì…ë³„ ì‘ë‹µ
    if (errorMessage.includes('503') || errorMessage.includes('overloaded')) {
      return NextResponse.json(
        { error: 'AI ì„œë²„ê°€ ì¼ì‹œì ìœ¼ë¡œ ë°”ë¹ ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' },
        { status: 503 }
      )
    }

    if (errorMessage.includes('API_KEY')) {
      return NextResponse.json(
        { error: 'ì„œë²„ ì„¤ì • ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”' },
        { status: 500 }
      )
    }

    return NextResponse.json(
      { error: 'ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' },
      { status: 500 }
    )
  }
}
